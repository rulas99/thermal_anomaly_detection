{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thermal_anomalies_DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rulas99/thermal_anomaly_detection/blob/main/thermal_anomalies_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Segmentation [source](https://towardsdatascience.com/train-neural-net-for-semantic-segmentation-with-pytorch-in-50-lines-of-code-830c71a6544f)"
      ],
      "metadata": {
        "id": "aekdsIGqHvuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "alFBr4KgC-gb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision.models.segmentation\n",
        "import torch\n",
        "import torchvision.transforms as tf\n",
        "\n",
        "from pandas import read_csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "164j9ty19a8I",
        "outputId": "fe36a244-67e2-4801-da89-deb6d6c22a45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Learning_Rate = 1e-5\n",
        "width = 500\n",
        "height = 500 # image width and height\n",
        "batchSize = 7"
      ],
      "metadata": {
        "id": "7N5s4KO5wC0h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True) # Load net\n",
        "\n",
        "Net.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 3 classes\n",
        "\n",
        "Net = Net.to(device) # Set net to GPU or CPU\n",
        "\n",
        "optimizer = torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) # Create adam optimizer\n",
        "\n",
        "weights = torch.FloatTensor([0.1,1]).cuda()\n",
        "criterion = torch.nn.CrossEntropyLoss(weight = weights) # Set loss function"
      ],
      "metadata": {
        "id": "Lx6dEFuLwLkK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=read_csv(\"/content/drive/MyDrive/segment_sentinel2_hotspot/train_2.csv\")"
      ],
      "metadata": {
        "id": "PRKw-z48wAVu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)),tf.ToTensor(),])\n",
        "                         #tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "                         \n",
        "transformAnn=tf.Compose([tf.ToPILImage(),tf.Resize((height,width),tf.InterpolationMode.NEAREST),tf.ToTensor()])"
      ],
      "metadata": {
        "id": "cr6fGoMHAgsQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReadRandomImage(): # First lets load random image and  the corresponding annotation\n",
        "    idx=np.random.randint(0,len(train)) # Select random image\n",
        "    thermal = cv2.imread(train.ori_path.iloc[idx])\n",
        "    masked =  cv2.imread(train.label_path.iloc[idx],0)\n",
        "    AnnMap = np.zeros(thermal.shape[0:2],np.float32)\n",
        "    if masked is not None:  AnnMap[ masked == 255 ] = 1\n",
        "    Img=transformImg(thermal)\n",
        "    AnnMap=transformAnn(AnnMap)\n",
        "    return Img,AnnMap\n",
        "\n",
        "\n",
        "def LoadBatch(): # Load batch of images\n",
        "    images = torch.zeros([batchSize,3,height,width])\n",
        "    ann = torch.zeros([batchSize, height, width])\n",
        "    for i in range(batchSize):\n",
        "        images[i],ann[i]=ReadRandomImage()\n",
        "    return images, ann"
      ],
      "metadata": {
        "id": "yRdqSGrxwJMk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for itr in range(300): # Training loop\n",
        "   images,ann=LoadBatch() # Load taining batch\n",
        "   images=torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
        "   ann = torch.autograd.Variable(ann, requires_grad=False).to(device) # Load annotation\n",
        "   Pred=Net(images)['out'] # make prediction\n",
        "   optimizer.zero_grad()\n",
        "   Loss=criterion(Pred,ann.long()) # Calculate cross entropy loss\n",
        "   Loss.backward() # Backpropagate loss\n",
        "   optimizer.step() # Apply gradient descent change to weight\n",
        "\n",
        "   if itr % 20 == 0: #Save model weight once every 100 steps permenant file\n",
        "        accG = [(torch.argmax(Pred[i], 0).cpu().detach().numpy() == ann[i].cpu().detach().numpy()).sum()/(width*height) for i in range(batchSize)]\n",
        "        accM = round(sum(accG)/batchSize,5)\n",
        "        loss = round(float(Loss.data.cpu()),5)\n",
        "        print(itr,f\") Loss = {loss} -- Accuracy = {accM}\")\n",
        "        print(f\"Saving model_{itr}.torch\")\n",
        "        torch.save(Net.state_dict(),   f'/content/drive/MyDrive/segment_sentinel2_hotspot/Models_2/model_{itr}.torch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prG5whv_wQtH",
        "outputId": "87b65166-5951-4114-eb5e-dc943ebebb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ) Loss = 0.74058 -- Accuracy = 0.26743\n",
            "Saving model_0.torch\n",
            "20 ) Loss = 0.72773 -- Accuracy = 0.4052\n",
            "Saving model_20.torch\n",
            "40 ) Loss = 0.71368 -- Accuracy = 0.40753\n",
            "Saving model_40.torch\n",
            "60 ) Loss = 0.68198 -- Accuracy = 0.54018\n",
            "Saving model_60.torch\n",
            "80 ) Loss = 0.65246 -- Accuracy = 0.7413\n",
            "Saving model_80.torch\n",
            "100 ) Loss = 0.61761 -- Accuracy = 0.83764\n",
            "Saving model_100.torch\n",
            "120 ) Loss = 0.56387 -- Accuracy = 0.96291\n",
            "Saving model_120.torch\n",
            "140 ) Loss = 0.48335 -- Accuracy = 0.98987\n",
            "Saving model_140.torch\n",
            "160 ) Loss = 0.44075 -- Accuracy = 0.98601\n",
            "Saving model_160.torch\n",
            "180 ) Loss = 0.41747 -- Accuracy = 0.99519\n",
            "Saving model_180.torch\n",
            "200 ) Loss = 0.38832 -- Accuracy = 0.99498\n",
            "Saving model_200.torch\n",
            "220 ) Loss = 0.3557 -- Accuracy = 0.99751\n",
            "Saving model_220.torch\n",
            "240 ) Loss = 0.34138 -- Accuracy = 0.995\n",
            "Saving model_240.torch\n",
            "260 ) Loss = 0.33476 -- Accuracy = 0.99433\n",
            "Saving model_260.torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9go_naQxAwNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}